version: "3.8"

services:
  traefik:
    image: traefik:v2.6.2
    ports:
      # Exposes port 80 for incomming web requests
      - "80:80"
      # The Web UI port http://0.0.0.0:8080 (enabled by --api.insecure=true)
      - "8080:8080"
      - "3306:3306"
      - "10009:10009"
      - "8020:8020"
      - "8032:8032"
      - "9866:9866"
    volumes:
      # So that Traefik can listen to the Docker events
      - /var/run/docker.sock:/var/run/docker.sock
      - ./app/traefik/conf/traefik.yml:/etc/traefik/traefik.yml
    deploy:
      update_config:
        delay: 10s
        order: start-first
      placement:
        constraints:
          - node.role == manager
  
  viz:
    image: alexellis2/visualizer-arm:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    deploy:
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.viz.rule=Host(`$VIZ_DNS`)"
        - "traefik.http.routers.viz.entrypoints=web"
        - "traefik.http.routers.viz.service=viz"
        - "traefik.http.services.viz.loadbalancer.server.port=8080"

  mysql-hive:
    image: mariadb:10.7
    environment: 
      - "MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD"
    deploy:
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.tcp.services.mysql-hive.loadbalancer.server.port=3306"
        - "traefik.tcp.routers.mysql-hive.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.mysql-hive.entrypoints=mysql"
    volumes:
      - "./db/mysql/dump/hive/2.3.9:/docker-entrypoint-initdb.d"

  kyuubi:
    image: ${SPARK_IMAGE}
    build: https://github.com/jsminet/docker-apache-spark.git#kyuubi-1.6.0-incubating
    hostname: kyuubi
    environment:
      - "KYUUBI_CONF_DIR=$KYUUBI_CONF_DIR"
      - "SPARK_CONF_DIR=$KYUUBI_CONF_DIR"
      - "HADOOP_CONF_DIR=$KYUUBI_CONF_DIR"
      - "KYUUBI_WORK_DIR_ROOT=$KYUUBI_WORK_DIR_ROOT"
    deploy:
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.tcp.routers.kyuubi.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.kyuubi.entrypoints=kyuubi"
        - "traefik.tcp.services.kyuubi.loadbalancer.server.port=$KYUUBI_FRONTEND_BIND_PORT"
    command: kyuubi
    volumes:
      - "./app/kyuubi:/app/kyuubi"
      - "./jars/drivers/mysql:/jars/drivers/mysql"
      - "spark3:/opt/apache-kyuubi-1.6.0-incubating-bin/externals/spark-3.2.1-bin-hadoop3.2"

  sparkmaster:
    image: ${SPARK_IMAGE}
    build: https://github.com/jsminet/docker-apache-spark.git#kyuubi-1.6.0-incubating
    hostname: sparkmaster
    environment:
      - "SPARK_MASTER_PORT=$SPARK_MASTER_PORT"
      - "SPARK_MASTER_WEBUI_PORT=$SPARK_MASTER_WEBUI_PORT"
      - "SPARK_CONF_DIR=$SPARK_CONF_DIR"
      - "HADOOP_CONF_DIR=$KYUUBI_CONF_DIR"
    deploy:
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.sparkmaster.rule=Host(`$SPARK_MASTER_DNS`)"
        - "traefik.http.routers.sparkmaster.entrypoints=web"
        - "traefik.http.routers.sparkmaster.service=sparkmaster"
        - "traefik.http.services.sparkmaster.loadbalancer.server.port=$SPARK_MASTER_WEBUI_PORT"
    volumes:
      - "./app/spark:/app/spark"
      - "./jars/drivers/mysql:/jars/drivers/mysql"
      - "spark3:/opt/apache-kyuubi-1.6.0-incubating-bin/externals/spark-3.2.1-bin-hadoop3.2"

  sparkworker:
    image: ${SPARK_IMAGE}
    build: https://github.com/jsminet/docker-apache-spark.git#kyuubi-1.6.0-incubating
    hostname: "sparkworker{{.Task.Slot}}"
    environment:
      - "SPARK_WORKER_CORES=$SPARK_WORKER_CORES"
      - "SPARK_WORKER_MEMORY=$SPARK_WORKER_MEMORY"
      - "SPARK_CONF_DIR=$SPARK_CONF_DIR"
      - "HADOOP_CONF_DIR=$KYUUBI_CONF_DIR"
    deploy:
      mode: replicated
      replicas: 3
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == worker
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.sparkworker.rule=Host(`$SPARK_WORKER_DNS`)"
        - "traefik.http.routers.sparkworker.entrypoints=web"
        - "traefik.http.routers.sparkworker.service=sparkworker"
        - "traefik.http.services.sparkworker.loadbalancer.server.port=$SPARK_WORKER_WEBUI_PORT"
    command: worker spark://sparkmaster:$SPARK_MASTER_PORT
    volumes:
      - "./app/spark:/app/spark"
      - "./jars/drivers/mysql:/jars/drivers/mysql"
      - "spark3:/opt/apache-kyuubi-1.6.0-incubating-bin/externals/spark-3.2.1-bin-hadoop3.2"

  namenode:
    image: ${HADOOP_IMAGE}
    build: ${HADOOP_GIT_URL}
    # We set labels to tell Traefik to assign a hostname to the new service
    hostname: namenode
    deploy:
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == manager
      labels:
          - "traefik.enable=true"
          - "traefik.http.routers.namenode.rule=Host(`$NAMENODE_DNS`)"
          - "traefik.http.routers.namenode.entrypoints=web"
          - "traefik.http.routers.namenode.service=namenode"
          - "traefik.http.services.namenode.loadbalancer.server.port=$DFS_NAMENODE_HTTP_PORT"
          - "traefik.tcp.routers.namenode.rule=HostSNI(`*`)"
          - "traefik.tcp.routers.namenode.entrypoints=namenode"
          - "traefik.tcp.services.namenode.loadbalancer.server.port=$DFS_NAMENODE_RPC_PORT"
    environment: 
      - "DFS_NAMENODE_RPC_BIND_HOST=$DFS_NAMENODE_RPC_BIND_HOST"
      - "YARN_RESOURCEMANAGER_HOSTNAME=$YARN_RESOURCEMANAGER_HOSTNAME"
      - "DFS_REPLICATION=$DFS_REPLICATION"
      - "HADOOP_CONF_DIR=$HADOOP_CONF_DIR"
    volumes: 
      - "./app/hadoop/conf/etc/hadoop:$HADOOP_CONF_DIR"
      #- "./app/hadoop/data/namenode:$DFS_NAMENODE_NAME_DIR"

  datanode1:
    image: ${HADOOP_IMAGE}
    build: ${HADOOP_GIT_URL}
    hostname: ${DATANODE1_DNS}
    deploy:
      placement:
        constraints:
          - node.role == worker
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.datanode1.rule=Host(`$DATANODE1_DNS`)"
        - "traefik.http.routers.datanode1.entrypoints=web"
        - "traefik.http.routers.datanode1.service=datanode1"
        - "traefik.http.services.datanode1.loadbalancer.server.port=$DFS_DATANODE_HTTP_PORT"
        - "traefik.tcp.routers.datanode1.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.datanode1.entrypoints=datanode"
        - "traefik.tcp.services.datanode1.loadbalancer.server.port=$DFS_DATANODE_RPC_PORT"
    environment: 
      - "DFS_NAMENODE_RPC_BIND_HOST=$DFS_NAMENODE_RPC_BIND_HOST"
      - "YARN_RESOURCEMANAGER_HOSTNAME=$YARN_RESOURCEMANAGER_HOSTNAME"
      - "DFS_REPLICATION=$DFS_REPLICATION"
      - "HADOOP_CONF_DIR=$HADOOP_CONF_DIR"
    command: datanode
    volumes: 
      - "./app/hadoop/conf/etc/hadoop:$HADOOP_CONF_DIR"
      #- "./app/hadoop/data/datanode:$DFS_DATANODE_NAME_DIR"

  datanode2:
    image: ${HADOOP_IMAGE}
    build: ${HADOOP_GIT_URL}
    hostname: ${DATANODE2_DNS}
    deploy:
      placement:
        constraints:
          - node.role == worker
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.datanode2.rule=Host(`$DATANODE2_DNS`)"
        - "traefik.http.routers.datanode2.entrypoints=web"
        - "traefik.http.routers.datanode2.service=datanode2"
        - "traefik.http.services.datanode2.loadbalancer.server.port=$DFS_DATANODE_HTTP_PORT"
        - "traefik.tcp.routers.datanode2.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.datanode2.entrypoints=datanode"
        - "traefik.tcp.services.datanode2.loadbalancer.server.port=$DFS_DATANODE_RPC_PORT"
    environment: 
      - "DFS_NAMENODE_RPC_BIND_HOST=$DFS_NAMENODE_RPC_BIND_HOST"
      - "YARN_RESOURCEMANAGER_HOSTNAME=$YARN_RESOURCEMANAGER_HOSTNAME"
      - "DFS_REPLICATION=$DFS_REPLICATION"
      - "HADOOP_CONF_DIR=$HADOOP_CONF_DIR"
    command: datanode
    volumes: 
      - "./app/hadoop/conf/etc/hadoop:$HADOOP_CONF_DIR"
      #- "./app/hadoop/data/datanode:$DFS_DATANODE_NAME_DIR"

  datanode3:
    image: ${HADOOP_IMAGE}
    build: ${HADOOP_GIT_URL}
    hostname: ${DATANODE3_DNS}
    deploy:
      placement:
        constraints:
          - node.role == worker
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.datanode3.rule=Host(`$DATANODE3_DNS`)"
        - "traefik.http.routers.datanode3.entrypoints=web"
        - "traefik.http.routers.datanode3.service=datanode3"
        - "traefik.http.services.datanode3.loadbalancer.server.port=$DFS_DATANODE_HTTP_PORT"
        - "traefik.tcp.routers.datanode3.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.datanode3.entrypoints=datanode"
        - "traefik.tcp.services.datanode3.loadbalancer.server.port=$DFS_DATANODE_RPC_PORT"
    environment: 
      - "DFS_NAMENODE_RPC_BIND_HOST=$DFS_NAMENODE_RPC_BIND_HOST"
      - "YARN_RESOURCEMANAGER_HOSTNAME=$YARN_RESOURCEMANAGER_HOSTNAME"
      - "DFS_REPLICATION=$DFS_REPLICATION"
      - "HADOOP_CONF_DIR=$HADOOP_CONF_DIR"
    command: datanode
    volumes: 
      - "./app/hadoop/conf/etc/hadoop:$HADOOP_CONF_DIR"
      #- "./app/hadoop/data/datanode:$DFS_DATANODE_NAME_DIR"

  zookeeper:
    image: zookeeper:latest
    hostname: zookeeper
    volumes: 
      - "./app/zookeeper/conf:$ZOOKEEPER_CONF_DIR"

  zeppelin:
    image: zeppelin:latest
    hostname: zeppelin
    environment:
      - "SPARK_MASTER=spark://sparkmaster:7077"
      - "HADOOP_CONF_DIR=$KYUUBI_CONF_DIR"
      - "SPARK_HOME=/opt/spark"
      - "ZEPPELIN_CONF_DIR=$ZEPPELIN_CONF_DIR"
      - "ZEPPELIN_LOG_DIR=$ZEPPELIN_LOG_DIR"
      - "ZEPPELIN_NOTEBOOK_DIR=$ZEPPELIN_NOTEBOOK_DIR"
    deploy:
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.zeppelin.rule=Host(`$ZEPPELIN_DNS`)"
        - "traefik.http.routers.zeppelin.entrypoints=web"
        - "traefik.http.routers.zeppelin.service=zeppelin"
        - "traefik.http.services.zeppelin.loadbalancer.server.port=$ZEPPELIN_HTTP_PORT"
        - "traefik.http.routers.zeppelin2.rule=Host(`$ZEPPELIN_SPARKUI_DNS`)"
        - "traefik.http.routers.zeppelin2.entrypoints=web"
        - "traefik.http.routers.zeppelin2.service=zeppelin2"
        - "traefik.http.services.zeppelin2.loadbalancer.server.port=$SPARK_UI_PORT"
    volumes:
      - "./app/zeppelin:/app/zeppelin"
      - "./app/kyuubi:/app/kyuubi"
      - "spark3:/opt/spark"

volumes: 
  spark3: