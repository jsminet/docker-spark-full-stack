version: "3.8"

services:
  traefik:
    image: traefik:v2.9.6
    ports:
      # Exposes port 80 for incomming web requests
      - 80:80
      # The Web UI port http://0.0.0.0:8080 (enabled by --api.insecure=true)
      - 8080:8080
      - 3306:3306
      - 10009:10009
      - 8020:8020
      - 8032:8032
      - 9866:9866
    volumes:
      # So that Traefik can listen to the Docker events
      - /var/run/docker.sock:/var/run/docker.sock
      - ./app/traefik/conf/traefik.yml:/etc/traefik/traefik.yml
    deploy:
      update_config:
        delay: 10s
        order: start-first
      placement:
        constraints:
          - node.role == manager
  
  viz:
    image: alexellis2/visualizer-arm:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    deploy:
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.viz.rule=Host(`$VIZ_DNS`)"
        - "traefik.http.routers.viz.entrypoints=web"
        - "traefik.http.routers.viz.service=viz"
        - "traefik.http.services.viz.loadbalancer.server.port=8080"

  mysql-hive:
    image: mariadb:10.7
    environment: 
      - "MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD"
    deploy:
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.tcp.services.mysql-hive.loadbalancer.server.port=3306"
        - "traefik.tcp.routers.mysql-hive.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.mysql-hive.entrypoints=mysql"
    volumes:
      - "./db/mysql/dump/hive/3.1.0:/docker-entrypoint-initdb.d"

  kyuubi:
    image: ${SPARK_IMAGE}
    build: $KYUUBI_GIT_URL
    hostname: kyuubi
    environment:
      - "KYUUBI_CONF_DIR=$KYUUBI_CONF_DIR"
      - "SPARK_CONF_DIR=$KYUUBI_CONF_DIR"
      - "HADOOP_CONF_DIR=$KYUUBI_CONF_DIR"
      - "KYUUBI_WORK_DIR_ROOT=$KYUUBI_WORK_DIR_ROOT"
    deploy:
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.tcp.routers.kyuubi.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.kyuubi.entrypoints=kyuubi"
        - "traefik.tcp.services.kyuubi.loadbalancer.server.port=$KYUUBI_FRONTEND_BIND_PORT"
    command: kyuubi
    volumes:
      - "./app/kyuubi:/app/kyuubi"
      - "./jars/drivers/mysql:/jars/drivers/mysql"
      - "spark3:$KYUUBI_SPARK_HOME"
      - "hive3:/root/.ivy2"

  sparkmaster:
    image: ${SPARK_IMAGE}
    build: $KYUUBI_GIT_URL
    hostname: ${SPARK_MASTER_DNS}
    environment:
      - "SPARK_MASTER_PORT=$SPARK_MASTER_PORT"
      - "SPARK_MASTER_WEBUI_PORT=$SPARK_MASTER_WEBUI_PORT"
      - "SPARK_CONF_DIR=$SPARK_CONF_DIR"
      - "HADOOP_CONF_DIR=$KYUUBI_CONF_DIR"
    deploy:
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.sparkmaster.rule=Host(`$SPARK_MASTER_DNS`)"
        - "traefik.http.routers.sparkmaster.entrypoints=web"
        - "traefik.http.routers.sparkmaster.service=sparkmaster"
        - "traefik.http.services.sparkmaster.loadbalancer.server.port=$SPARK_MASTER_WEBUI_PORT"
    volumes:
      - "./app/spark:/app/spark"
      - "./jars/drivers/mysql:/jars/drivers/mysql"
      - "spark3:$KYUUBI_SPARK_HOME"

  sparkworker:
    image: ${SPARK_IMAGE}
    build: $KYUUBI_GIT_URL
    hostname: "sparkworker{{.Task.Slot}}"
    environment:
      - "SPARK_WORKER_CORES=$SPARK_WORKER_CORES"
      - "SPARK_WORKER_MEMORY=$SPARK_WORKER_MEMORY"
      - "SPARK_CONF_DIR=$SPARK_CONF_DIR"
      - "HADOOP_CONF_DIR=$KYUUBI_CONF_DIR"
    deploy:
      mode: replicated
      replicas: 3
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == worker
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.sparkworker.rule=Host(`$SPARK_WORKER_DNS`)"
        - "traefik.http.routers.sparkworker.entrypoints=web"
        - "traefik.http.routers.sparkworker.service=sparkworker"
        - "traefik.http.services.sparkworker.loadbalancer.server.port=$SPARK_WORKER_WEBUI_PORT"
    command: worker spark://sparkmaster:$SPARK_MASTER_PORT
    volumes:
      - "./app/spark:/app/spark"
      - "./jars/drivers/mysql:/jars/drivers/mysql"
      - "spark3:$KYUUBI_SPARK_HOME"

  namenode:
    image: ${HADOOP_IMAGE}
    build: ${HADOOP_GIT_URL}
    # We set labels to tell Traefik to assign a hostname to the new service
    hostname: ${NAMENODE_DNS}
    deploy:
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == manager
      labels:
          - "traefik.enable=true"
          - "traefik.http.routers.namenode.rule=Host(`$NAMENODE_DNS`)"
          - "traefik.http.routers.namenode.entrypoints=web"
          - "traefik.http.routers.namenode.service=namenode"
          - "traefik.http.services.namenode.loadbalancer.server.port=$DFS_NAMENODE_HTTP_PORT"
          - "traefik.tcp.routers.namenode.rule=HostSNI(`*`)"
          - "traefik.tcp.routers.namenode.entrypoints=namenode"
          - "traefik.tcp.services.namenode.loadbalancer.server.port=$DFS_NAMENODE_RPC_PORT"
    environment: 
      - "DFS_NAMENODE_RPC_BIND_HOST=$DFS_NAMENODE_RPC_BIND_HOST"
      - "YARN_RESOURCEMANAGER_HOSTNAME=$YARN_RESOURCEMANAGER_HOSTNAME"
      - "DFS_REPLICATION=$DFS_REPLICATION"
      - "HADOOP_CONF_DIR=$HADOOP_CONF_DIR"
    volumes: 
      - "./app/hadoop/conf/etc/hadoop:$HADOOP_CONF_DIR"
      #- "./app/hadoop/data/namenode:$DFS_NAMENODE_NAME_DIR"

  datanode1:
    image: ${HADOOP_IMAGE}
    build: ${HADOOP_GIT_URL}
    hostname: ${DATANODE1_DNS}
    deploy:
      placement:
        constraints:
          - node.role == worker
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.datanode1.rule=Host(`$DATANODE1_DNS`)"
        - "traefik.http.routers.datanode1.entrypoints=web"
        - "traefik.http.routers.datanode1.service=datanode1"
        - "traefik.http.services.datanode1.loadbalancer.server.port=$DFS_DATANODE_HTTP_PORT"
        - "traefik.tcp.routers.datanode1.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.datanode1.entrypoints=datanode"
        - "traefik.tcp.services.datanode1.loadbalancer.server.port=$DFS_DATANODE_RPC_PORT"
    environment: 
      - "DFS_NAMENODE_RPC_BIND_HOST=$DFS_NAMENODE_RPC_BIND_HOST"
      - "YARN_RESOURCEMANAGER_HOSTNAME=$YARN_RESOURCEMANAGER_HOSTNAME"
      - "DFS_REPLICATION=$DFS_REPLICATION"
      - "HADOOP_CONF_DIR=$HADOOP_CONF_DIR"
    command: datanode
    volumes: 
      - "./app/hadoop/conf/etc/hadoop:$HADOOP_CONF_DIR"
      #- "./app/hadoop/data/datanode:$DFS_DATANODE_NAME_DIR"

  datanode2:
    image: ${HADOOP_IMAGE}
    build: ${HADOOP_GIT_URL}
    hostname: ${DATANODE2_DNS}
    deploy:
      placement:
        constraints:
          - node.role == worker
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.datanode2.rule=Host(`$DATANODE2_DNS`)"
        - "traefik.http.routers.datanode2.entrypoints=web"
        - "traefik.http.routers.datanode2.service=datanode2"
        - "traefik.http.services.datanode2.loadbalancer.server.port=$DFS_DATANODE_HTTP_PORT"
        - "traefik.tcp.routers.datanode2.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.datanode2.entrypoints=datanode"
        - "traefik.tcp.services.datanode2.loadbalancer.server.port=$DFS_DATANODE_RPC_PORT"
    environment: 
      - "DFS_NAMENODE_RPC_BIND_HOST=$DFS_NAMENODE_RPC_BIND_HOST"
      - "YARN_RESOURCEMANAGER_HOSTNAME=$YARN_RESOURCEMANAGER_HOSTNAME"
      - "DFS_REPLICATION=$DFS_REPLICATION"
      - "HADOOP_CONF_DIR=$HADOOP_CONF_DIR"
    command: datanode
    volumes: 
      - "./app/hadoop/conf/etc/hadoop:$HADOOP_CONF_DIR"
      #- "./app/hadoop/data/datanode:$DFS_DATANODE_NAME_DIR"

  datanode3:
    image: ${HADOOP_IMAGE}
    build: ${HADOOP_GIT_URL}
    hostname: ${DATANODE3_DNS}
    deploy:
      placement:
        constraints:
          - node.role == worker
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.datanode3.rule=Host(`$DATANODE3_DNS`)"
        - "traefik.http.routers.datanode3.entrypoints=web"
        - "traefik.http.routers.datanode3.service=datanode3"
        - "traefik.http.services.datanode3.loadbalancer.server.port=$DFS_DATANODE_HTTP_PORT"
        - "traefik.tcp.routers.datanode3.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.datanode3.entrypoints=datanode"
        - "traefik.tcp.services.datanode3.loadbalancer.server.port=$DFS_DATANODE_RPC_PORT"
    environment: 
      - "DFS_NAMENODE_RPC_BIND_HOST=$DFS_NAMENODE_RPC_BIND_HOST"
      - "YARN_RESOURCEMANAGER_HOSTNAME=$YARN_RESOURCEMANAGER_HOSTNAME"
      - "DFS_REPLICATION=$DFS_REPLICATION"
      - "HADOOP_CONF_DIR=$HADOOP_CONF_DIR"
    command: datanode
    volumes: 
      - "./app/hadoop/conf/etc/hadoop:$HADOOP_CONF_DIR"
      #- "./app/hadoop/data/datanode:$DFS_DATANODE_NAME_DIR"

  zookeeper:
    image: zookeeper:latest
    hostname: zookeeper
    volumes: 
      - "./app/zookeeper/conf:$ZOOKEEPER_CONF_DIR"

  zeppelin:
    image: zeppelin:latest
    hostname: ${ZEPPELIN_DNS}
    environment:
      - "SPARK_MASTER=spark://sparkmaster:7077"
      - "HADOOP_CONF_DIR=$KYUUBI_CONF_DIR"
      - "SPARK_HOME=/opt/spark"
      - "ZEPPELIN_CONF_DIR=$ZEPPELIN_CONF_DIR"
      - "ZEPPELIN_LOG_DIR=$ZEPPELIN_LOG_DIR"
      - "ZEPPELIN_NOTEBOOK_DIR=$ZEPPELIN_NOTEBOOK_DIR"
    deploy:
      endpoint_mode: dnsrr
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.zeppelin.rule=Host(`$ZEPPELIN_DNS`)"
        - "traefik.http.routers.zeppelin.entrypoints=web"
        - "traefik.http.routers.zeppelin.service=zeppelin"
        - "traefik.http.services.zeppelin.loadbalancer.server.port=$ZEPPELIN_HTTP_PORT"
        - "traefik.http.routers.zeppelin2.rule=Host(`$ZEPPELIN_SPARKUI_DNS`)"
        - "traefik.http.routers.zeppelin2.entrypoints=web"
        - "traefik.http.routers.zeppelin2.service=zeppelin2"
        - "traefik.http.services.zeppelin2.loadbalancer.server.port=$SPARK_UI_PORT"
    volumes:
      - "./app/zeppelin:/app/zeppelin"
      - "./app/kyuubi:/app/kyuubi"
      - "spark3:/opt/spark"

volumes: 
  spark3:
  hive3: