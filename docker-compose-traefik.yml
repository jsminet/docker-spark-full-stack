version: '3.7'

services:
  traefik:
    image: traefik:v2.5
    ports:
      # Exposes port 80 for incomming web requests
      - "80:80"
      # The Web UI port http://0.0.0.0:8080 (enabled by --api.insecure=true)
      - "8080:8080"
      - "3306:3306"
      - "10009:10009"
    volumes:
      # So that Traefik can listen to the Docker events
      - /var/run/docker.sock:/var/run/docker.sock
      - ./app/traefik/conf/traefik.yml:/etc/traefik/traefik.yml
    deploy:
      placement:
        constraints:
          - node.role == manager
  
  viz:
    image: alexellis2/visualizer-arm:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    deploy:
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.viz.rule=Host(`$VIZ_DNS`)"
        - "traefik.http.routers.viz.entrypoints=web"
        - "traefik.http.routers.viz.service=viz"
        - "traefik.http.services.viz.loadbalancer.server.port=8080"

  mysql-hive:
    image: mariadb:10.7
    environment: 
      - "MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD"
    deploy:
      labels:
        - "traefik.enable=true"
        - "traefik.tcp.services.mysql-hive.loadbalancer.server.port=3306"
        - "traefik.tcp.routers.mysql-hive.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.mysql-hive.entrypoints=mysql"
    volumes:
      - "./db/mysql/dump/hive/2.3.9:/docker-entrypoint-initdb.d"
    
  spark-master:
    image: ${SPARK_IMAGE}
    build: https://github.com/jsminet/docker-apache-spark.git#kyuubi-1.2.0
    # We set a label to tell Traefik to assign a hostname to the new service
    deploy:
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.spark-master.rule=Host(`$SPARK_DNS`)"
        - "traefik.http.routers.spark-master.entrypoints=web"
        - "traefik.http.routers.spark-master.service=spark-master"
        - "traefik.http.services.spark-master.loadbalancer.server.port=$SPARK_MASTER_WEBUI_PORT"
    environment: 
      - "SPARK_MASTER_PORT=$SPARK_MASTER_PORT"
      - "SPARK_MASTER_WEBUI_PORT=$SPARK_MASTER_WEBUI_PORT"
      - "SPARK_CONF_DIR=$SPARK_CONF_DIR"
      - "SPARK_LOG_DIR=$SPARK_LOG_DIR/master"
    volumes:
      - "./app/spark:/app/spark"

  spark-worker-1:
    image: ${SPARK_IMAGE}
    environment: 
      - "SPARK_WORKER_CORES=$SPARK_WORKER_CORES"
      - "SPARK_WORKER_MEMORY=$SPARK_WORKER_MEMORY"
      - "SPARK_CONF_DIR=$SPARK_CONF_DIR"
      - "SPARK_LOG_DIR=$SPARK_LOG_DIR/worker1"
      - "SPARK_WORKER_DIR=$SPARK_WORKER_DIR/worker1"
    command: worker spark://spark-master:$SPARK_MASTER_PORT
    volumes:
      - "./app/spark:/app/spark"
      - "./drivers/mysql:/drivers/mysql"

  kyuubi:
    image: ${SPARK_IMAGE}
    environment:
      - "KYUUBI_CONF_DIR=$KYUUBI_CONF_DIR"
      - "SPARK_CONF_DIR=$KYUUBI_CONF_DIR"
      - "HADOOP_CONF_DIR=$KYUUBI_CONF_DIR"
      - "KYUUBI_WORK_DIR_ROOT=$KYUUBI_WORK_DIR_ROOT"
    deploy:
      placement:
        constraints:
          - node.role == manager
      labels:
        - "traefik.enable=true"
        - "traefik.tcp.routers.kyuubi.rule=HostSNI(`*`)"
        - "traefik.tcp.routers.kyuubi.entrypoints=other"
        - "traefik.tcp.routers.kyuubi.service=kyuubi"
        - "traefik.tcp.services.kyuubi.loadbalancer.server.port=$KYUUBI_FRONTEND_BIND_PORT"
    command: kyuubi
    volumes:
      - "./app/kyuubi:/app/kyuubi"
      - "./drivers/mysql:/drivers/mysql"

  namenode:
    image: ${HADOOP_IMAGE}
    build: https://github.com/jsminet/docker-apache-hadoop.git#3.2.2
    # We set labels to tell Traefik to assign a hostname to the new service
    hostname: namenode
    deploy:
      placement:
        constraints:
          - node.role == manager
      labels:
          - "traefik.enable=true"
          - "traefik.http.routers.namenode.rule=Host(`$HADOOP_DNS`)"
          - "traefik.http.routers.namenode.entrypoints=web"
          - "traefik.http.routers.namenode.service=namenode"
          - "traefik.http.services.namenode.loadbalancer.server.port=$DFS_NAMENODE_HTTP_PORT"
    environment: 
      - "DFS_NAMENODE_RPC_BIND_HOST=$DFS_NAMENODE_RPC_BIND_HOST"
      - "HADOOP_CONF_DIR=$HADOOP_CONF_DIR"
    volumes: 
      - "./app/hadoop/conf/etc/hadoop:$HADOOP_CONF_DIR"

  datanode-1:
    image: ${HADOOP_IMAGE}
    environment: 
      - "DFS_NAMENODE_RPC_BIND_HOST=$DFS_NAMENODE_RPC_BIND_HOST"
      - "HADOOP_CONF_DIR=$HADOOP_CONF_DIR"
    command: datanode
    volumes: 
      - "./app/hadoop/conf/etc/hadoop:$HADOOP_CONF_DIR"